# LLM (llama.cpp server)
LLM_HOST=127.0.0.1
LLM_MODEL_PATH=e4.gguf
LLM_PORT=8080
# Search API (FastAPI + Tavily)
API_MODEL=tavily-web
API_HOST=127.0.0.1
API_PORT=8000
TAVILY_API_KEY=

# Web UI
WEB_POLL_TIMER_MS=8000
WEB_TELEMETRY_MS=10000
UI_BROWSER_CMD=

# Python environment for FastAPI search server
PYTHON_ENV_PATH=/home/cix/search
SEARCH_VENV_PATH=/home/cix/search
POWER_IDLE_WATTS=16
POWER_MAX_WATTS=64
